{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraping Soccer Data\n",
    "### Getting data from English, Italian, German, and Spanish Soccer leagues\n",
    "\n",
    "In this section, we will use [Sky Sports](https://www.skysports.com/) to gather our standings and results from the years where we have trade data, as they have results in an easy to parse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our function to get our data\n",
    "def fetch_data(url, lg, yr, df, cols):\n",
    "    \n",
    "    # get the html from our passed url\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "    # initialize our variables we want to capture\n",
    "    pos = [] \n",
    "    team = [] \n",
    "    pl = []\n",
    "    w = []\n",
    "    d = []\n",
    "    l = []\n",
    "    f = []\n",
    "    a = []\n",
    "    gd = []\n",
    "    pts = []\n",
    "    \n",
    "    # get the table object\n",
    "    table = soup.find(class_ = 'standing-table__table')\n",
    "    \n",
    "    # find the table body \n",
    "    b = table.find('tbody').find_all('tr')\n",
    "    \n",
    "    # loop through each table row and add the next value to the corresponding list\n",
    "    for tr in b:\n",
    "        td = tr.find_all('td')\n",
    "        pos.append(td[0].text.strip())\n",
    "        team.append(td[1].text.strip())\n",
    "        pl.append(td[2].text.strip())\n",
    "        w.append(td[3].text.strip())\n",
    "        d.append(td[4].text.strip())\n",
    "        l.append(td[5].text.strip())\n",
    "        f.append(td[6].text.strip())\n",
    "        a.append(td[7].text.strip())\n",
    "        gd.append(td[8].text.strip())\n",
    "        pts.append(td[9].text.strip())\n",
    "\n",
    "    # combine our fields into a dataframe    \n",
    "    out = pd.DataFrame(list(zip(pos, team, pl, w, d, l, f, a, gd, pts)), \n",
    "                      columns = cols)\n",
    "    # add the year and league from our search and return the data frame\n",
    "    out['Year'] = yr\n",
    "    out['League'] = lg\n",
    "    df = df.append(out, ignore_index = True, sort = False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find our base url\n",
    "base_url = 'https://www.skysports.com/'\n",
    "\n",
    "# create our list of additional pieces of our URL\n",
    "labels = ['premier-league', 'serie-a', 'la-liga', 'bundesliga']\n",
    "labels = [i + '-table/' for i in labels]\n",
    "\n",
    "# create our full list of urls\n",
    "urls = [base_url + i for i in labels]\n",
    "year = [str(i) for i in range(2018, 2008 - 1, -1)]\n",
    "urls = [i + j for i in urls for j in year]\n",
    "\n",
    "# create our list of years and leagues\n",
    "league = np.repeat(['epl', 'serie a', 'la liga', 'bundesliga'], len(urls)/4)\n",
    "years = year * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed: epl 2018\n",
      "completed: epl 2017\n",
      "completed: epl 2016\n",
      "completed: epl 2015\n",
      "completed: epl 2014\n",
      "completed: epl 2013\n",
      "completed: epl 2012\n",
      "completed: epl 2011\n",
      "completed: epl 2010\n",
      "completed: epl 2009\n",
      "completed: epl 2008\n",
      "completed: serie a 2018\n",
      "completed: serie a 2017\n",
      "completed: serie a 2016\n",
      "completed: serie a 2015\n",
      "completed: serie a 2014\n",
      "completed: serie a 2013\n",
      "completed: serie a 2012\n",
      "completed: serie a 2011\n",
      "completed: serie a 2010\n",
      "completed: serie a 2009\n",
      "completed: serie a 2008\n",
      "completed: la liga 2018\n",
      "completed: la liga 2017\n",
      "completed: la liga 2016\n",
      "completed: la liga 2015\n",
      "completed: la liga 2014\n",
      "completed: la liga 2013\n",
      "completed: la liga 2012\n",
      "completed: la liga 2011\n",
      "completed: la liga 2010\n",
      "completed: la liga 2009\n",
      "completed: la liga 2008\n",
      "completed: bundesliga 2018\n",
      "completed: bundesliga 2017\n",
      "completed: bundesliga 2016\n",
      "completed: bundesliga 2015\n",
      "completed: bundesliga 2014\n",
      "completed: bundesliga 2013\n",
      "completed: bundesliga 2012\n",
      "completed: bundesliga 2011\n",
      "completed: bundesliga 2010\n",
      "completed: bundesliga 2009\n",
      "completed: bundesliga 2008\n",
      "\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# initialize an empty data frame\n",
    "cols = ['Position', 'Team', 'Played', 'W', 'D', 'L', 'GF', 'GA', 'GD', 'PTS']\n",
    "df = pd.DataFrame(columns = cols)\n",
    "\n",
    "# try to loop through our urls, years, and leagues to gather our data\n",
    "for i in range(len(urls)):\n",
    "    try:\n",
    "        df = fetch_data(url = urls[i],\n",
    "                        lg = league[i], \n",
    "                        yr = years[i], \n",
    "                        df = df, \n",
    "                        cols = cols)\n",
    "        print('completed:', league[i], years[i])\n",
    "    except:\n",
    "        pass\n",
    "print()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write our results to a csv\n",
    "df.to_csv('league_results.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our results, we can combine that with the other data in the Transfer Analysis notebook to analyze our trades"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
